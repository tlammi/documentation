# OpenCL notes

Notes from book OpenCL Programming Guide

# Terms and abreviations
- load balancing - The act of sharing the computation to different resources


- GPGPU - general purpose GPU
- PE - processing element

# Chapter 1: Introduction
- Pros for manycore systems include lower power usage and better scalability. (P = V^2*C*f)
- OpenCL encourages using all platform resources instead of splitting a functionality per block

## Conseptual Foundations of OpenCL
1. **Discover:** Discover the components that make up the heterogenous system
2. **Probe:** Probe the caracteristics of these components so that the software can adapt to the specific features of different hardware elements
3. **Create kernels:** Create the blocks of instructions (kernels) that will run on the platform
4. **Configure memory objects:** Set up and manipulate memory objects involved in the computation
5. **Execute kernels:** Execute the kernels in the right order and on the right components of the system
6. **Collect results:** Collect the final results

## OpenCL Models
- Platform model - A high-level description of heterogenous system
- Execution model - How streams of instructions execute
- Memory model - the collection of memory regions
- Programming models - High-level models a programmer uses when designing algorithms to implement applications

## Execution Model
- OpenCL supports external and internal kernels
  - Internal kernels are compiled with OpenCL compiler
  - External kernels are specified e.g. in host's source code and are accessed from OpenCL e.g. via function pointers
- The command that submits a kernel for execution creates a collection of work-items, each of which uses the same sequence of instructions defined
  by a single kernel.
- Work-items are organized into work-groups
- Work-groups are the same size in each dimension and together span the whole global index space
- Work-items in a given work-group execute concurrently on the processing elements of a single computing unit
- **OpenCL only assures that work-items are executed concurrently**
   - Kernel and work-group executions can be serialized
- OpenCL index space is spans and N-dimensioned range of values, therefore it is called *NDRange*
  - Inside OpenCL program the NDRange is defined by an integer array with length N
  - Each working item's global and local ID is an N-dimensional tuple

### Theory

Let NDRange be 2-dimensional and work-items have a global coordinate *(g<sub>x</sub>, g<sub>y</sub>)* in a *(G<sub>x</sub>, G<sub>y</sub>)* 
global index space, where *g<sub>i</sub>* &#8712; [0, *G<sub>i</sub>*-1].  
Let work-group ID be *(w<sub>x</sub>, w<sub>y</sub>)* and index space *(W<sub>x</sub>, W<sub>y</sub>)* in a similar manner.  
Let work-item have al local coordinate marked with *l* in the similar manner.

Since OpenCL specifies that work-groups evenly divide the whole NDRange in each dimension, the local index space can be defined as:  
> L<sub>i</sub> = G<sub>i</sub>/W<sub>i</sub>, where i &#8712; {x,y}  

and global ID as:  
> g<sub>i</sub> = w<sub>i</sub> * L<sub>i</sub> + l<sub>i</sub>

And alternatively:
> w<sub>i</sub> = floor(g<sub>i</sub>/L<sub>i</sub>)  
> l<sub>i</sub> = g<sub>i</sub> mod L<sub>i</sub>

OpenCL also supports specifying an index range starting fron another index than 0 changing the equations to:
> g<sub>i</sub> = w<sub>i</sub>*L<sub>i</sub> + l<sub>i</sub> + o<sub>i</sub>  
> w<sub>i</sub> = floor((g<sub>i</sub>-o<sub>i</sub>)/L<sub>i</sub>)  
> l<sub>i</sub> = g<sub>i</sub> mod L<sub>i</sub> - o<sub>i</sub>  

### Context
The first task of the host is to define the context for OpenCL application, i.e. the environment in which the kernel are defined and execute.  
Context is defined in terms of following resources:
- Devices: the collection of OpenCL devices to be used by the host
- Kernels: the OpenCL functions that run on OpenCL devices
- Program objects: the program source code and executables that implement the kernels
- Memory Objects: a set of objects in memory that are visible to OpenCL devices and contain values that can be operated on by the kernel instances

The context can be e.g: two multicore CPUs and a GPU where one of the cores on the other CPU is the host which then decides how to use
the other resources via OpenCL to perform the computations. Program objects used by the OpenCL are typically strings either compiled into
host's source code, loaded from a file or dynamically generated by the program. The runtime compilation is done as the platform is not fully
known during the development. User could e.g. run the solution on platforms with different GPUs. Memory objects provide a unified memory structure
for all devices. This is needed since devices often have a range of different memory architectures in use.

### Command-queues

Command-queues provide the medium of for transferring commands between host and OpenCL. Host creates a command-queue and 
assigns it with the required device. After this the commands passed to a command-queue are then forwarded to the selected
device. OpenCL supports three types of commands:
- **Kernel execution commands** execute a kernel on the processing element of an OpenCL device
- **Memory commands** transfer data between the host and different memory objects,  
move data between memory objets, or map and unmap memory objects from the host address space.
- **Synchronization commands** put constraints on the order in which commands execute.

A typical host program functions by first defining the context and the command-queues then defining memory objects and program objects.
Then the program builds all data structures required by the on the host to support the application. After this the focus shifts to command
queues: Memory objects are moved to the devices, kernel arguments are attached to the memory objects and then sumitted to the command-queue for execution.
When the kernel has completed its work, the memory objects produced by the computation may be copied back onto the host. If e.g. multiple kernels
are specified at a time, additional synchronization commands are required to configure the interraction between them. By default all of the
operations are performed asynchronously to the host.

Commands within a single queue execute relative to each other in one of two modes:
1. **In-order execution**: Commands are launched in the order in which they appear in the command-queue and complete in order. In other
words, a prior command on the queue completes before the the following command begins.
2. **Out-of-order execution**: Commands are issued in order but do not wait to complete before the following commands execute. Any order constraints
are enforced by the programmer through explicit synchronization mechanisms.

All OpenCL platforms support In-order execution but the out-of-order mode is optional.

## Memory Model
